---
title: "My personal notes on processing the .lift and .flextext exported data"
output: 
  github_document:
    toc: true
author: '[Gede Primahadi Wijaya Rajeg](https://www.ling-phil.ox.ac.uk/people/gede-rajeg) <a itemprop="sameAs" content="https://orcid.org/0000-0002-2047-8621" href="https://orcid.org/0000-0002-2047-8621" target="orcid.widget" rel="noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon"></a><br>University of Oxford, UK & Universitas Udayana, Indonesia'
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(tidyverse)
lu_form_df <- read_rds("../FLEX-lift-pre-fieldwork.rds")
```

<!-- badges: start -->
[![The University of Oxford](../file-oxweb-logo.gif){width="84"}](https://www.ox.ac.uk/) [![Faculty of Linguistics, Philology and Phonetics, the University of Oxford](../file-lingphil.png){width="83"}](https://www.ling-phil.ox.ac.uk/) [![Arts and Humanities Research Council (AHRC)](../file-ahrc.png){width="325"}](https://www.ukri.org/councils/ahrc/) </br>*This work is part of the [AHRC-funded project (AH/W007290/1)](https://app.dimensions.ai/details/grant/grant.12915105) on the lexical resources for Enggano, led by the Faculty of Linguistics, Philology and Phonetics at the University of Oxford, UK. Visit the [central webpage of the Enggano project](https://enggano.ling-phil.ox.ac.uk/)*.
<!-- badges: end -->

# Code file for processing the exported .lift data from FLEx `Lexicon`

The code file to process the .lift export from FLEx `Lexicon` is [FLEX-contemporary-with-examples-new.R](https://github.com/engganolang/eno-flex/blob/main/FLEX-contemporary-with-examples-new.R). This code file is the basis for the following output data, namely:

1. "`FLEX-lift-pre-fieldwork.rds`" (as per 2023)

1. "`FLEX-lift-march-2024.rds`" (as per March 2024 project meeting at Udayana University)

# Code files for processing the exported .flextext data from FLEx interlinear text in `Texts and Words`

The codes to process the .flextext export data need to be run in the order given below. However, before these codes are run, I need to fix anomaly in the .flextext output based on the notes given in [all-contemp-interlinear-texts-NOTES.txt](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/all-contemp-interlinear-texts-NOTES.txt).

(@flextext-code-1) [processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW.R](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW.R)

**Description** : This code file in [(@flextext-code-1)](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW.R) processes the .flextext data for the natural language corpus (see the `A. Natural texts` section in the code) and elicitation materials (see the `B. Elicitation` section in the code).

**Input data**: 

- The input file for the natural corpus is "`contemporary-enggano-interlinear-text/all-contemp-texts-with-idn-gloss-march2024.flextext`" (for the March Project Meeting 2024 version) and "`contemporary-enggano-interlinear-text/all-contemp-texts-with-idn-gloss.flextext`" (for the older, post first fieldwork version in late 2023). 

- The input file for the elicitation data is "`contemporary-enggano-interlinear-text/all-contemp-elicitation-march2024.flextext`" (for the March Project Meeting 2024 version) and "`contemporary-enggano-interlinear-text/all-contemp-elicitation.flextext`" (for the older, post first fieldwork version in late 2023). 

**Output data**: The codes in [(@flextext-code-1)](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW.R) generates the output data in .rds. 

- The first is .rds file for the original texts and their English and Indonesian translation in tibble format (the combined/binded one from the list version appears in "`contemporary-enggano-interlinear-text/eno_contemp_text_only_as_tibble-new-binded-march2024.rds`" for the natural corpus and in "`contemporary-enggano-interlinear-text/eno_contemp_elicitation_only_as_tibble-new-binded-march2024.rds`" for the elicitation). 

- The second .rds data generated by [(@flextext-code-1)](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW.R) is for the words/lexicon (generated via the for-loop in the code file); this data appears as tibbles in "`contemporary-enggano-interlinear-text/eno_contemp_text_as_tibble-new-march2024.rds`" for the natural corpus and in "`contemporary-enggano-interlinear-text/eno_contemp_elicitation_as_tibble-new-march2024.rds`" for the elicitation.

-------------------------------

(@flextext-code-2) [processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW-splitting-morpheme.R](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW-splitting-morpheme.R) (NB. this code is called from within the code to generate the SFM file; cf. code file in (@flextext-code-3) below)

-------------------------------

(@flextext-code-3) [processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW-SFM.R](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW-SFM.R) (NB. from within this code, we call the following two codes: [processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW-splitting-morpheme.R](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW-splitting-morpheme.R) (code file @flextext-code-2) and [gloss_fixing.R](https://github.com/engganolang/eno-flex/blob/main/contemporary-enggano-interlinear-text/gloss_fixing.R))

# The exported .lift data from FLEx `Lexicon`

The latest, exported `Lexicon` data based on the code file [FLEX-contemporary-with-examples-new.R](https://github.com/engganolang/eno-flex/blob/main/FLEX-contemporary-with-examples-new.R) (pre- and post-October-2023 fieldwork called `FLEX-lift-pre-fieldwork.rds`, or the March 2024 version called `FLEX-lift-march-2024.rds`) contains some example sentences for certain lexical entries. This leads to the presence of duplicated observation in `FLEX-lift-pre-fieldwork.rds`/`FLEX-lift-march-2024.rds` (to be read into R as `lu_form_df` tibble). The example sentences are contained in the `"x_eno"`, `"x_idn"`, and `"x_eng"` columns of the `lu_form_df`.

Even though the `x_...` columns for example sentences have been excluded and then the `distinct()` function has been run, there are still duplicates due to the presence of multiple senses of a given lexical entry. These multiple senses (shown in the `"sense_gloss_en"` and/or `"sense_gloss_idn"` column of the `lu_form_df` tibble) are represented into different rows. The example is *ueh* that is glossed as 'sleep' and 'lie'. Hence, *ueh* has two entries/rows in `lu_form_df`.

The following code shows how to get the entries that are duplicated due to having more than one sense/gloss.

```{r get-duplicated-entries, message=FALSE, warning=FALSE}
duplicated_entries <- lu_form_df |> 
  
  # exclude the example sentences column
  select(!matches("^x_")) |> 
  
  # get distinct observation
  distinct() |> 
  
  # count the number of entry_id, showing there are duplicated entries, still.
  count(entry_id, sort = TRUE)

duplicated_entries
```


The following code shows preview of entries with multiple senses.

```{r show-duplicated-entries}
lu_form_df |> 
  
  # From the `duplicated_entries` tibble above,
  # filter only `"entry_id"` column whose occurrences are more than once,
  # suggesting that such entry has more than one sense/gloss.
  filter(entry_id %in% pull(filter(duplicated_entries, n > 1),
                            entry_id)) |> 
  
  # Print the relevant columns
  select(entry_id, form, sense_order, sense_gloss_en, sense_gloss_idn)
```


# On `eno_word_id`

- IMPORTANT: The same word form may have different `eno_word_id` because this same word form comes from different texts!

- For example, the word "kapa'ueh" 'put; lay down' has three unique IDs because these three IDs are coming from three different texts for this one word.

# Textbook materials

This section contains my notes to process the textbook-based print dictionary from the .flextext and .lift outputs.

- Ensure in FLEx gloss tab that the writing system keyboard in each free translation field is a match!

    - If this is not the case, the use of English keyboard in Indonesian field will render the language element of the .flextext output as "en" for this Indonesian field.

## Processing steps

Here are the steps to follow.

1. Export from FLEx Analyze tab the .flextext file

1. Export from FLEx LEXICON feature the .lift file

1. The processing of the .flextext and .lift files:

    1. First run: the C section in `processing-all-contemporary-texts-ELAN-FLEX-flextext-NEW.R` that contains the code to turn the .flextext xml file into a tabular format. This will generate the data **`contemporary-enggano-interlinear-text/textbook_lexicon_as_tibble_oct-2024.rds`**
    
    1. Second run: the R code file `textbook-LIFT-processing-code.R` to process the LIFT export that generates this .rds file **`contemporary-enggano-interlinear-text/textbook-LIFT.rds`**.
    
        a. The morpheme splitting for the lexical entries is available from this code file: `textbook-splitting-code.R`
        
    1. Third run: the R code `textbook-SFM.R` for turning .LIFT and .flextext into SFM
    
## On importing to FLEx

This note records entry to merge between FLORA & FAUNA data, Cultural Items data, and Textbook materials. The SFM of FLORA & FAUNA is separately processed from Cultural Items + Textbook materials.

### Entries to merge

1. puru 'leaf' (delete the third sense duplicate of *puru*)

1. it 'banana' 

    - merge sense 2 banana (that has image) with sense 1 also banana (coming from textbook materials)
    
1. abeh 'bambu' (-merge sense as well)

1. akė 'patah' (-merge sense as well)

1. amai 'tebu'

1. ame 'kima'

1. anima

1. anu'un

1. apu 'jenis kayu'

1. apu' 'snake'

1. are'iar 'belalang' (check the NAs!)

1. arkih 'beras'
    
1. bak kaha' 'sun' and 'clock'

1. bakayė 'sirsak'

1. be 'anjing'

1. bih 'lebah'

1. dadė 'cabe'

1. dih 'daun muda; pucuk'; CHECK the glossing for "dih nan"

1. dudiad 'durian'

1. ea 'tulang'

1. eai 'ikan'

1. CHECK hapu̇-hapu̇ dop

1. hia

### Change sub-entries from derivative to variant

1. teb/tem

1. anah 'thus'

1. Apoho

1. arib he aru 'seven' (check the orig. FLEx file)

1. bahem

1. Bakaor

NOTE : for this section, it has been fixed in the R code (esp. in `textbook-splitting-code.R`) where I identified a variable for grouping words as complex forms when the morph_gloss_en contains `__`, which I use as a separator for morpheme-by-morpheme glossing of the complex forms. So, if words have these morpheme structures, they are treated as subentries of the root (to distinguish them with variant)





# On sub-entries

## Sub-entries type

1. The SFM can include custom marker indicating the specific type of the sub-entries.

1. In the new FLEx project, set up the corresponding specific sub-entry types in the List for "Complex Form Types".

    1. This specific sub-entry type is given in the Name and Abbreviation fields.
    
    1. The Reverse Name and Reverse Abbr. of the specific sub-entry type is also prepared in the FLEx List.
    
1. Finally, in the mapping during import, I will only specify the specific sub-entry types with the custom marker, without the need to create marker for the Reverse Name and Reverse Abbr.

1. __TO DO (DONE)__: prepare the list of the relevant complex form types for matching between SFM Marker and FLEx List. (DONE)
